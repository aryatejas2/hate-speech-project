{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\Tejas\\Desktop\\Capstone\\DatasetsCleaned\\UniformClasses\\V2\\train\\ohc_train.csv', sep='\\t')\n",
    "df_test = pd.read_csv(r'C:\\Users\\Tejas\\Desktop\\Capstone\\DatasetsCleaned\\UniformClasses\\V2\\test\\ohc_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8285 8285\n",
      "2090 2090\n"
     ]
    }
   ],
   "source": [
    "xtrain = df_train['Text']\n",
    "ytrain = df_train['Class']\n",
    "xtest = df_test['Text']\n",
    "ytest = df_test['Class']\n",
    "\n",
    "print(len(xtrain), len(ytrain))\n",
    "print(len(xtest), len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(list(xtrain) + list(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sequences = tokenizer.texts_to_sequences(xtrain)\n",
    "xtest_sequences = tokenizer.texts_to_sequences(xtest)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(list(ytrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(xtrain_sequences, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(xtest_sequences, maxlen=maxlen)\n",
    "y_train = np.array(label_tokenizer.texts_to_sequences(ytrain))\n",
    "y_test = np.array(label_tokenizer.texts_to_sequences(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 128)          2857216   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,956,161\n",
      "Trainable params: 2,956,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\Tejas\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\Tejas\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\Tejas\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Tejas\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Tejas\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train,\n",
    "           validation_data=[x_test, y_test], \n",
    "           epochs=5, \n",
    "           batch_size=2048, \n",
    "           steps_per_epoch=10)\n",
    "# print(history.history['loss'])\n",
    "# print(history.history['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4e9bb6295ff9e4931e9608a5097b50fffdac6915fea455a24d8ada659b972b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('hsp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
